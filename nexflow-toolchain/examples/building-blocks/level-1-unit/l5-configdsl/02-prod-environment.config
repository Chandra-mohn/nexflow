// =============================================================================
// L5-02: Production Environment Configuration
// =============================================================================
// Use Case: Configure job for production deployment
// Pattern:  High availability, security, monitoring, scaling
// When:     Production deployment, staging validation
// =============================================================================

environment production
    description "Production environment configuration"

    // Kafka configuration - production cluster
    kafka:
        bootstrap_servers: "${KAFKA_BROKERS:kafka-1:9092,kafka-2:9092,kafka-3:9092}"

        consumer:
            group_id: "${APP_NAME}-consumer"
            auto_offset_reset: "latest"
            enable_auto_commit: false
            max_poll_records: 500
            session_timeout_ms: 30000
            heartbeat_interval_ms: 10000
        end

        producer:
            acks: "all"
            retries: 3
            retry_backoff_ms: 1000
            enable_idempotence: true
            compression_type: "snappy"
            batch_size: 16384
            linger_ms: 10
        end

        // Security
        security:
            protocol: "SASL_SSL"
            sasl_mechanism: "PLAIN"
            sasl_username: "${KAFKA_USERNAME}"
            sasl_password: "${KAFKA_PASSWORD}"
            ssl_truststore_location: "/etc/kafka/truststore.jks"
            ssl_truststore_password: "${TRUSTSTORE_PASSWORD}"
        end
    end

    // Flink configuration - production cluster
    flink:
        parallelism: "${FLINK_PARALLELISM:8}"

        checkpoint:
            enabled: true
            interval: 30000
            timeout: 60000
            min_pause: 10000
            max_concurrent: 1
            mode: "exactly_once"
            directory: "s3://${S3_BUCKET}/flink/checkpoints/${APP_NAME}"
        end

        state_backend: "rocksdb"
        rocksdb:
            incremental: true
            block_cache_size: "256mb"
        end

        restart_strategy:
            type: "exponential_delay"
            initial_backoff: "1s"
            max_backoff: "60s"
            backoff_multiplier: 2.0
            max_attempts: 10
        end

        // Resource allocation
        resources:
            task_manager_memory: "4g"
            task_slots: 4
        end
    end

    // Database connections - production
    database:
        primary:
            url: "jdbc:postgresql://${DB_HOST}:5432/${DB_NAME}"
            username: "${DB_USERNAME}"
            password: "${DB_PASSWORD}"
            pool_size: 20
            max_lifetime: 1800000
            connection_timeout: 30000
            validation_query: "SELECT 1"
        end

        replica:
            url: "jdbc:postgresql://${DB_REPLICA_HOST}:5432/${DB_NAME}"
            username: "${DB_USERNAME}"
            password: "${DB_PASSWORD}"
            pool_size: 10
            read_only: true
        end
    end

    // Redis cluster for caching
    redis:
        mode: "cluster"
        nodes: "${REDIS_NODES:redis-1:6379,redis-2:6379,redis-3:6379}"
        password: "${REDIS_PASSWORD}"
        connection_timeout: 5000
        socket_timeout: 2000
        max_redirects: 3
    end

    // Logging - structured JSON for aggregation
    logging:
        level: "${LOG_LEVEL:INFO}"
        format: "json"
        include_stacktrace: false
        fields:
            app_name: "${APP_NAME}"
            environment: "production"
            version: "${APP_VERSION}"
        end
    end

    // Metrics - Prometheus export
    metrics:
        enabled: true
        type: "prometheus"
        port: 9090
        path: "/metrics"
        labels:
            app: "${APP_NAME}"
            env: "production"
        end
        histograms:
            enabled: true
            buckets: [0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10]
        end
    end

    // Health checks
    health:
        port: 8080
        liveness_path: "/health/live"
        readiness_path: "/health/ready"
        startup_probe:
            initial_delay: 30
            period: 10
        end
    end

    // Alerting thresholds
    alerts:
        consumer_lag_threshold: 10000
        processing_latency_threshold_ms: 5000
        error_rate_threshold_percent: 1.0
    end

    // Feature flags
    features:
        enable_detailed_logging: false
        enable_debug_endpoints: false
        enable_rate_limiting: true
        enable_circuit_breaker: true
    end

    // Rate limiting
    rate_limiting:
        enabled: true
        requests_per_second: 1000
        burst_size: 2000
    end

    // Circuit breaker
    circuit_breaker:
        failure_threshold: 5
        success_threshold: 3
        timeout_seconds: 30
        half_open_requests: 3
    end
end

// -----------------------------------------------------------------------------
// Variation: Staging environment (production-like)
// -----------------------------------------------------------------------------

environment staging
    description "Staging environment - production replica"

    // Inherit production settings with overrides
    extends: production

    kafka:
        bootstrap_servers: "${STAGING_KAFKA_BROKERS}"
        consumer:
            group_id: "${APP_NAME}-staging-consumer"
        end
    end

    flink:
        parallelism: 4
        checkpoint:
            directory: "s3://${STAGING_S3_BUCKET}/flink/checkpoints/${APP_NAME}"
        end
    end

    database:
        primary:
            url: "jdbc:postgresql://${STAGING_DB_HOST}:5432/${DB_NAME}"
            pool_size: 10
        end
    end

    logging:
        level: "DEBUG"
        fields:
            environment: "staging"
        end
    end

    features:
        enable_detailed_logging: true
        enable_debug_endpoints: true
    end
end

// =============================================================================
// What This Generates:
// - Production-grade configuration
// - Security credentials from environment variables
// - High availability settings
// - Monitoring and alerting configuration
//
// Production Essentials:
// - Kafka: SSL/SASL security, exactly-once, idempotent producer
// - Flink: RocksDB state backend, checkpointing to S3
// - Database: Connection pooling, read replicas
// - Redis: Cluster mode, authentication
// - Logging: Structured JSON, correlation IDs
// - Metrics: Prometheus export, custom histograms
// - Health: Kubernetes-style health probes
// - Resilience: Circuit breaker, rate limiting
//
// Configuration Inheritance:
// - `extends: production` for staging/prod-like environments
// - Override specific settings as needed
//
// Next Steps:
// → Level 4: Complete applications with production config
// → CI/CD: Environment-specific deployment pipelines
// =============================================================================
