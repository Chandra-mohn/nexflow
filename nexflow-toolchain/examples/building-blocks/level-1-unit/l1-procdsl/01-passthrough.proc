// =============================================================================
// L1-01: Passthrough (Kafka → Kafka)
// =============================================================================
// Use Case: Forward events from one topic to another without modification
// Pattern:  Identity transformation - read and write unchanged
// When:     Topic migration, multi-consumer isolation, development/testing
// =============================================================================

process order_forwarder
    // Read from source Kafka topic with schema
    receive orders
        from kafka "orders_input"
        schema order

    // Write to destination Kafka topic (unchanged)
    emit to orders_output
        schema order
end

// =============================================================================
// What This Generates:
// - Flink DataStream job with KafkaSource and KafkaSink
// - Exactly-once semantics (default)
// - No transformation logic - pure passthrough
//
// Schema Reference:
// - order: L2 SchemaDSL definition for order events
//
// Next Steps:
// → L1-02: Add filtering with route using rules
// → L12-01: Add schema validation (L1+L2)
// =============================================================================
