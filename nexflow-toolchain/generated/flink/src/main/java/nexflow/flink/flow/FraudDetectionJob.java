/**
 * FraudDetectionJob
 *
 * Flink Streaming Job for process: fraud_detection
 *
 * AUTO-GENERATED by Nexflow Code Generator
 * DO NOT EDIT - Changes will be overwritten
 */
package nexflow.flink.flow;

import java.time.Duration;
import org.apache.flink.api.common.eventtime.WatermarkStrategy;
import org.apache.flink.connector.base.DeliveryGuarantee;
import org.apache.flink.connector.kafka.sink.KafkaRecordSerializationSchema;
import org.apache.flink.connector.kafka.sink.KafkaSink;
import org.apache.flink.connector.kafka.source.KafkaSource;
import org.apache.flink.connector.kafka.source.enumerator.initializer.OffsetsInitializer;
import org.apache.flink.streaming.api.CheckpointingMode;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.kafka.clients.consumer.OffsetResetStrategy;

public class FraudDetectionJob {

    // Job Configuration
    private static final String JOB_NAME = "fraud_detection";
    private static final int DEFAULT_PARALLELISM = 8;
    private static final String KAFKA_BOOTSTRAP_SERVERS = 
        System.getenv().getOrDefault("KAFKA_BOOTSTRAP_SERVERS", "localhost:9092");

    public static void main(String[] args) throws Exception {
        // Create execution environment
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        env.setParallelism(DEFAULT_PARALLELISM);

        // Build and execute pipeline
        FraudDetectionJob job = new FraudDetectionJob();
        job.buildPipeline(env);

        // Execute
        env.execute(JOB_NAME);
    }

    /**
     * Build the streaming pipeline.
     */
    public void buildPipeline(StreamExecutionEnvironment env) {

        // Source: kafka_transactions
        KafkaSource<Transaction> kafka_transactionsSource = KafkaSource
            .<Transaction>builder()
            .setBootstrapServers(KAFKA_BOOTSTRAP_SERVERS)
            .setTopics("kafka_transactions")
            .setGroupId("fraud_detection-consumer")
            .setStartingOffsets(OffsetsInitializer.committedOffsets(OffsetResetStrategy.EARLIEST))
            .build();

        DataStream<Transaction> kafkaTransactionsStream = env
            .fromSource(
                kafka_transactionsSource,
                WatermarkStrategy.<Transaction>forBoundedOutOfOrderness(Duration.ofMillis(5000)),
                "kafka_transactions"
            );


        // Checkpoint Configuration
        env.enableCheckpointing(60000, CheckpointingMode.EXACTLY_ONCE);
        env.getCheckpointConfig().setCheckpointStorage("s3_checkpoint");

        // Processing Pipeline
        // TODO: Wire up processing operators
        // - EnrichDecl: customer_lookup
        // - TransformDecl: normalize_amount
        // - RouteDecl: fraud_rules
        // - WindowDecl: tumbling window
        // - AggregateDecl: fraud_summary

        // Sinks
        // - emit to processed_transactions
        // - emit to fraud_alerts
    }

}